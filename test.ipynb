{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/workspace/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"Elfsong/QG-DPO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'chosen', 'rejected'],\n",
       "    num_rows: 4574\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds['train']\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'rejected_bp', 'rejected'],\n",
       "    num_rows: 4574\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.rename_column(\"chosen\", \"rejected_bp\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'rejected_bp', 'chosen'],\n",
       "    num_rows: 4574\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ds = ds.rename_column(\"rejected\", \"chosen\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'rejected', 'chosen'],\n",
       "    num_rows: 4574\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.rename_column(\"rejected_bp\", \"rejected\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'rejected', 'chosen'],\n",
       "    num_rows: 4574\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 245.78ba/s]\n",
      "Uploading the dataset shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.60s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Elfsong/QG-DPO-New/commit/c555bb1b5d82e8a8247a2edb7ad23eb56cddc9e2', commit_message='Upload dataset', commit_description='', oid='c555bb1b5d82e8a8247a2edb7ad23eb56cddc9e2', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/Elfsong/QG-DPO-New', endpoint='https://huggingface.co', repo_type='dataset', repo_id='Elfsong/QG-DPO-New'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.push_to_hub(\"Elfsong/QG-DPO-New\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://172.16.166.118:1234/v1\",\n",
    "    api_key=\"sk-1234\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='<think>\\n\\nOkay, the user wants me to introduce myself in rhymes. Let\\'s start with a catchy opening line that includes my name, Qwen. I should mention that I\\'m an AI created by Alibaba Cloud. Need to keep it playful and friendly.\\n\\nHmm, maybe something like \"Hello there, itâ€™s great to meet you,\" then rhyme with \"Iâ€™m Qwen, the AI whoâ€™s here for you!\" \\n\\nNext lines should explain my purpose: answering questions, solving problems, creative ideas too. Maybe \"Crafting tales or solving equations\" paired with \"Offering help without any conditions.\"\\n\\nThen add a touch of personality, like having fun and being wise. Something like \"With a dash of wit and a spark of play,\" followed by \"Iâ€™m here to assist in every way!\"\\n\\nWrap it up with an invitation for them to ask anything. Rhymes could be \"So donâ€™t hesitate, just give me a tryâ€” / Letâ€™s make today shine from the sky!\" \\n\\nWait, does that flow well? Maybe adjust lines to ensure rhythm and rhyme consistency. Also check syllable counts so each couplet matches. Alright, that should work. Let\\'s put it all together smoothly.\\n</think>\\n\\nHello there, itâ€™s great to meet you!  \\nIâ€™m Qwen, the AI whoâ€™s here for *you!*  \\nCrafting tales or solving equations,  \\nOffering help without any conditions.  \\n\\nWith a dash of wit and a spark of play,  \\nIâ€™m here to assist in every wayâ€”  \\nRhymes? Yep, Iâ€™ve got those on lock!  \\nCloud-born, curious, here to unlock:  \\n\\nYour questions, ideas, or midnight musings,  \\nA friendly guide with no delaysâ€”just *using*  \\nLogic, laughter, and a touch of flair,  \\nTo light up your day (no need to compare!).  \\n\\nSo ask away, letâ€™s chat and explore!  \\nThe worldâ€™s vastâ€”Iâ€™ll help you soar. ðŸŒŸ', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"qwq-32b\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Always answer in rhymes.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Introduce yourself.\"}\n",
    "  ],\n",
    "  temperature=0.7,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/QwQ-32B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"How many r's are in the word \\\"strawberry\\\"\"}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>user\\nHow many r\\'s are in the word \"strawberry\"<|im_end|>\\n<|im_start|>assistant\\n<think>\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monolith import monolith\n",
    "\n",
    "monolith = monolith.Monolith(backend_url='https://monolith.cool')\n",
    "\n",
    "post_response = monolith.post_code_submit(\n",
    "    lang = 'python3',\n",
    "    libs = [],\n",
    "    code = 'print(\"Hello, World!\")',\n",
    "    timeout = 10,\n",
    "    profiling = False\n",
    ")\n",
    "\n",
    "task_id = post_response['task_id']\n",
    "\n",
    "get_response = monolith.get_code_result(task_id)\n",
    "print(get_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_dict': {'code': 'print(\"Hello, World!\")', 'language': 'python3', 'libraries': [], 'run_memory_profile': False, 'timeout': 10}, 'output_dict': {'error': \"Language python3 is not supported. Must be one of ['python', 'java', 'javascript', 'cpp', 'go', 'ruby']\"}, 'status': 'error', 'task_id': 'd033abdc-096c-4e75-a16b-6c75933324b1', 'timestamp': 1742290581.852626, 'worker_id': 0}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
