{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/mingzhe/Projects/Afterburner\")\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import utils\n",
    "from openai import OpenAI\n",
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=\"https://api.studio.nebius.com/v1/\",\n",
    "    api_key=\"TOKEN\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATION_TEMPLATE = \"\"\"\n",
    "## Instructions\n",
    "You are an expert competitive programmer who excels at solving algorithm problems in multiple programming languages.\n",
    "Your task is to implement a solution to the following problem in {target_lang}.\n",
    "\n",
    "## Problem Description\n",
    "{question}\n",
    "\n",
    "## Starter Code\n",
    "{starter_code}\n",
    "\n",
    "## Output Format\n",
    "- Provide the complete solution code in **one markdown code block** with appropriate language identifier.\n",
    "- Implement the function with the exact signature (name, parameters, etc.) specified in the starter code.\n",
    "- EXCLUDE ALL explanations, code comments, import/package/library statements, additional classes or functions outside of the starter code scope, or starting code like `if __name__ == \"__main__\":` or `func main()` or `package main` or `using namespace std;`.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'apps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "venus_dataset = load_dataset(\"Elfsong/Venus_Python\", split=f\"test\")\n",
    "apps_dataset = load_dataset(\"Elfsong/Apps_Python\", split=f\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_list = list()\n",
    "for instance in venus_dataset if task == 'venus' else apps_dataset:\n",
    "    prompt = GENERATION_TEMPLATE.format(\n",
    "        target_lang=\"python\",\n",
    "        question=instance['question_content'] if task == 'venus' else instance['problem_content'],\n",
    "        starter_code=utils.wrap_code_block(\"python\", instance['code_prompt']),\n",
    "    )\n",
    "    request_body = {\n",
    "        \"custom_id\": f\"request-{instance['problem_id']}\", \n",
    "        \"method\": \"POST\", \n",
    "        \"url\": \"/v1/chat/completions\", \n",
    "        \"body\": {\n",
    "            \"model\": \"Qwen/QwQ-32B\", \n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": prompt}],\n",
    "            \"max_completion_tokens\": 8192*4\n",
    "        }\n",
    "    }\n",
    "    request_list.append(request_body)\n",
    "    \n",
    "with open(\"nebius_batch_requests.jsonl\", \"w\") as f:\n",
    "    for request in request_list:\n",
    "        f.write(json.dumps(request) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the file\n",
    "batch_requests = client.files.create(\n",
    "    file=open(\"nebius_batch_requests.jsonl\", \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "print(batch_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a batch\n",
    "response = client.batches.create(\n",
    "    input_file_id=batch_requests.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": f\"QwQ-32B {task} Generation\"\n",
    "    }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_e99adb9c-d359-47e5-978a-7e820c0a2698', completion_window='24h', created_at=1745697027, endpoint='/v1/chat/completions', input_file_id='file-d5cf6f24-ba7d-4da4-b265-ba7a8a2f8b27', object='batch', status='done', cancelled_at=None, cancelling_at=None, completed_at=1745700933, error_file_id=None, errors=None, expired_at=None, expires_at=None, failed_at=None, finalizing_at=1745700933, in_progress_at=1745697031, metadata={'description': 'Asynchronous job'}, output_file_id='39b7c2c6-1bc0-4b5b-9f4e-1bc7e63ed238', request_counts=BatchRequestCounts(completed=300, failed=0, total=300))\n",
      "Batch(id='batch_65c6c74f-e794-4c7d-b8fc-d0ac03a60098', completion_window='24h', created_at=1746189986, endpoint='/v1/chat/completions', input_file_id='file-60afa97b-7760-4c87-ad9e-f4694871f801', object='batch', status='done', cancelled_at=None, cancelling_at=None, completed_at=1746190930, error_file_id=None, errors=None, expired_at=None, expires_at=None, failed_at=None, finalizing_at=1746190929, in_progress_at=1746190002, metadata={'description': 'QwQ-32B Generation'}, output_file_id='0914724e-51ba-4099-bf9d-2468891fdd70', request_counts=BatchRequestCounts(completed=300, failed=0, total=300))\n",
      "Batch(id='batch_02e1fa29-9991-47eb-87f1-d70ba3ccd88f', completion_window='24h', created_at=1746191449, endpoint='/v1/chat/completions', input_file_id='file-16759e93-0460-4711-b0e1-8d9f30e7ea3d', object='batch', status='done', cancelled_at=None, cancelling_at=None, completed_at=1746195868, error_file_id=None, errors=None, expired_at=None, expires_at=None, failed_at=None, finalizing_at=1746195868, in_progress_at=1746191459, metadata={'description': 'QwQ-32B Generation'}, output_file_id='7b6a7aa2-ce32-4a2c-9178-c6e5d7c5871b', request_counts=BatchRequestCounts(completed=300, failed=0, total=300))\n",
      "Batch(id='batch_2072405d-5022-41fa-9ff6-7262095d04aa', completion_window='24h', created_at=1746197456, endpoint='/v1/chat/completions', input_file_id='file-a857b716-b208-4107-8e17-53fc76439cd0', object='batch', status='cancelled', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=None, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'QwQ-32B apps Generation'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=300))\n",
      "Batch(id='batch_2e840e54-eb30-4e07-97ed-e00aabfec2a0', completion_window='24h', created_at=1746196177, endpoint='/v1/chat/completions', input_file_id='file-a857b716-b208-4107-8e17-53fc76439cd0', object='batch', status='running', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=None, failed_at=None, finalizing_at=None, in_progress_at=1746196179, metadata={'description': 'QwQ-32B apps Generation'}, output_file_id=None, request_counts=BatchRequestCounts(completed=294, failed=0, total=300))\n",
      "Batch(id='batch_ce3a94de-45e0-49d1-b480-a7fc75c28702', completion_window='24h', created_at=1745693763, endpoint='/v1/chat/completions', input_file_id='file-67a21561-bee8-4b4d-8e0e-a2bcf707ca4f', object='batch', status='done', cancelled_at=None, cancelling_at=None, completed_at=1745695742, error_file_id=None, errors=None, expired_at=None, expires_at=None, failed_at=None, finalizing_at=1745695742, in_progress_at=1745693769, metadata={'description': 'Asynchronous job'}, output_file_id='8c5db2e1-1896-4818-8d61-380686d45849', request_counts=BatchRequestCounts(completed=300, failed=0, total=300))\n"
     ]
    }
   ],
   "source": [
    "for batch in client.batches.list():\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch status: done - BatchRequestCounts(completed=300, failed=0, total=300)\n"
     ]
    }
   ],
   "source": [
    "# Check the status of the batch\n",
    "status = 'processing'\n",
    "batch_id = \"batch_2e840e54-eb30-4e07-97ed-e00aabfec2a0\"\n",
    "while status != \"done\":\n",
    "    batch_info = client.batches.retrieve(batch_id)\n",
    "    status = batch_info.status\n",
    "    print(f'Batch status: {status} - {batch_info.request_counts}')\n",
    "    if status == \"done\": break\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results of the batch\n",
    "batch_result = client.files.content(batch_info.output_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-] No code blocks found. Will return the whole response.\n",
      "[-] No code blocks found. Will return the whole response.\n",
      "[-] No code blocks found. Will return the whole response.\n",
      "[-] No code blocks found. Will return the whole response.\n",
      "[-] No code blocks found. Will return the whole response.\n",
      "[-] No code blocks found. Will return the whole response.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee57d2fc9be42c7bc33206c06558625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f52bb4c1c0443fa498f883a9f0cad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de1f0cd539b745fba34192b340ff04d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "solutions = list()\n",
    "for line in batch_result.iter_lines():\n",
    "    instance = json.loads(line)\n",
    "    problem_id = instance['custom_id'].split('-')[1]\n",
    "    model_response = instance['response']['choices'][0]['message']['content']\n",
    "    \n",
    "    try:\n",
    "        code = utils.extract_code_blocks(model_response)[0]['code']\n",
    "    except Exception as e:\n",
    "        print(f\"[-] No code blocks found. Will return the whole response.\")\n",
    "        code = model_response\n",
    "    \n",
    "    solutions.append({\"problem_id\": problem_id, \"solution\": code})\n",
    "    \n",
    "ds = Dataset.from_list(solutions)\n",
    "if task == 'venus':\n",
    "    ds.push_to_hub(\"Elfsong/Venus_Model_Evaluation\", 'qwq_32b', private=True)\n",
    "else:\n",
    "    ds.push_to_hub(\"Elfsong/Apps_Model_Evaluation\", 'qwq_32b', private=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
