{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/mingzhe/Projects/Afterburner\")\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import utils\n",
    "from openai import OpenAI\n",
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=\"https://api.studio.nebius.com/v1/\",\n",
    "    api_key=\"eyJhbGciOiJIUzI1NiIsImtpZCI6IlV6SXJWd1h0dnprLVRvdzlLZWstc0M1akptWXBvX1VaVkxUZlpnMDRlOFUiLCJ0eXAiOiJKV1QifQ.eyJzdWIiOiJnb29nbGUtb2F1dGgyfDEwMjM1NjEzMDM1MDE1MTM1ODEwMiIsInNjb3BlIjoib3BlbmlkIG9mZmxpbmVfYWNjZXNzIiwiaXNzIjoiYXBpX2tleV9pc3N1ZXIiLCJhdWQiOlsiaHR0cHM6Ly9uZWJpdXMtaW5mZXJlbmNlLmV1LmF1dGgwLmNvbS9hcGkvdjIvIl0sImV4cCI6MTkwMjI1MTAwMiwidXVpZCI6Ijk1ZTE3NjYyLTc3NzUtNDkyMi04MmY5LTI1ZmJiNzA1NjhiYiIsIm5hbWUiOiJBZnRlcmJ1cm5lciIsImV4cGlyZXNfYXQiOiIyMDMwLTA0LTEyVDE5OjAzOjIyKzAwMDAifQ.XVPmE5ziJzrLanUqrPmEhd2l4sNuMsIZSSzsGCqWJZo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AFTERBURNER_GENERATION_TEMPLATE = \"\"\"\n",
    "## Instructions\n",
    "You are an expert competitive programmer who excels at solving algorithm problems in multiple programming languages.\n",
    "Your task is to implement a solution to the following problem in {target_lang}.\n",
    "\n",
    "## Problem Description\n",
    "{problem_description}\n",
    "\n",
    "## Original Solution\n",
    "```python\n",
    "{original_solution}\n",
    "```\n",
    "\n",
    "## Original Performance\n",
    "Passed: {original_passed} / Time: {original_time} / Memory: {original_memory} / Integral: {original_integral}\n",
    "\n",
    "## Output Format\n",
    "- Provide the complete solution code in **one markdown code block** with appropriate language identifier.\n",
    "- Fix the original solution if it was not passed. Optimize the {efficiency_instruction} performance if the original solution was passed.\n",
    "- EXCLUDE ALL explanations, code comments, import/package/library statements, additional classes or functions outside of the starter code scope, or starting code like `if __name__ == \"__main__\":` or `func main()` or `package main` or `using namespace std;`.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'venus'\n",
    "original_dataset_config = \"qwq_32b_integral_qwq_32b\"\n",
    "afterburner_dataset_config = \"qwq_32b\"\n",
    "afterburner_model_name = \"Qwen/QwQ-32B\"\n",
    "efficiency_instruction = \"integral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "venus_dataset = load_dataset(\"Elfsong/Venus_Python\", split=f\"test\")\n",
    "apps_dataset = load_dataset(\"Elfsong/Apps_Python\", split=f\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task == 'venus':\n",
    "    venus_generation_dataset = load_dataset(\"Elfsong/Venus_Model_Evaluation\", original_dataset_config, split=\"train\")\n",
    "else:\n",
    "    apps_generation_dataset = load_dataset(\"Elfsong/Apps_Model_Evaluation\", original_dataset_config, split=\"train\")\n",
    "\n",
    "solution_dict = dict()\n",
    "print(f\"[+] Loading {task} generation dataset...\")\n",
    "for instance in venus_generation_dataset if task == 'venus' else apps_generation_dataset:\n",
    "    solution_dict[int(instance['problem_id'])] = instance\n",
    "print(f\"[+] Loaded {len(solution_dict)} {task} generation instances.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venus_performance_dataset = load_dataset(\"Elfsong/Venus_Python_Model_Evaluation\", afterburner_dataset_config, split=\"train\")\n",
    "apps_performance_dataset = load_dataset(\"Elfsong/Apps_Python_Model_Evaluation\", afterburner_dataset_config, split=\"train\")\n",
    "\n",
    "performance_dict = dict()\n",
    "print(f\"[+] Loading {task} performance dataset...\")\n",
    "for instance in venus_performance_dataset if task == 'venus' else apps_performance_dataset:\n",
    "    problem_id = int(instance['problem_id'])\n",
    "    if problem_id not in performance_dict:\n",
    "        performance_dict[problem_id] = [instance]\n",
    "    else:\n",
    "        performance_dict[problem_id].append(instance)\n",
    "print(f\"[+] Loaded {len(performance_dict)} {task} performance instances.\")\n",
    "\n",
    "solution_performance_dict = dict()\n",
    "for problem_id in performance_dict:\n",
    "    original_code = solution_dict[problem_id]['solution']\n",
    "    \n",
    "    original_solutions = performance_dict[problem_id]\n",
    "    original_solution_passed = all(s['passed'] for s in original_solutions)\n",
    "    original_solution_time = sum(s['absolute_time'] for s in original_solutions) / len(original_solutions)\n",
    "    original_solution_memory = sum(s['absolute_memory'] for s in original_solutions) / len(original_solutions)\n",
    "    original_solution_integral = sum(s['absolute_integral'] for s in original_solutions) / len(original_solutions)\n",
    "    \n",
    "    solution_performance_dict[problem_id] = {\n",
    "        \"solution\": original_code,\n",
    "        \"passed\": original_solution_passed,\n",
    "        \"time\": original_solution_time,\n",
    "        \"memory\": original_solution_memory,\n",
    "        \"integral\": original_solution_integral\n",
    "    }\n",
    "print(f\"[+] Loaded {len(performance_dict)} {task} solution performance instances.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_list = list()\n",
    "for instance in venus_dataset if task == 'venus' else apps_dataset:\n",
    "    solution_performance_instance = solution_performance_dict[instance['problem_id']]\n",
    "    prompt = AFTERBURNER_GENERATION_TEMPLATE.format(\n",
    "        target_lang=\"python\",\n",
    "        problem_description=instance['question_content'] if task == 'venus' else instance['problem_content'],\n",
    "        efficiency_instruction=efficiency_instruction,\n",
    "        original_solution=solution_performance_instance['solution'],\n",
    "        original_passed=solution_performance_instance['passed'],\n",
    "        original_time=solution_performance_instance['time'],\n",
    "        original_memory=solution_performance_instance['memory'],\n",
    "        original_integral=solution_performance_instance['integral']\n",
    "    )\n",
    "    request_body = {\n",
    "        \"custom_id\": f\"request-{instance['problem_id']}\", \n",
    "        \"method\": \"POST\", \n",
    "        \"url\": \"/v1/chat/completions\", \n",
    "        \"body\": {\n",
    "            \"model\": afterburner_model_name, \n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": prompt}],\n",
    "            \"max_completion_tokens\": 8192*4\n",
    "        }\n",
    "    }\n",
    "    request_list.append(request_body)\n",
    "    \n",
    "with open(\"nebius_batch_requests.jsonl\", \"w\") as f:\n",
    "    for request in request_list:\n",
    "        f.write(json.dumps(request) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the file\n",
    "batch_requests = client.files.create(\n",
    "    file=open(\"nebius_batch_requests.jsonl\", \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "print(batch_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a batch\n",
    "response = client.batches.create(\n",
    "    input_file_id=batch_requests.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": f\"QwQ-32B {task} Generation\"\n",
    "    }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all batches\n",
    "for batch in client.batches.list():\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_id = \"batch_56cd406b-86ac-401f-bf55-f17eeadfe6cd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch status: running - BatchRequestCounts(completed=299, failed=0, total=300)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatch status: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_info\u001b[38;5;241m.\u001b[39mrequest_counts\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Check the status of the batch\n",
    "status = 'processing'\n",
    "batch_id = batch_id\n",
    "while status != \"done\":\n",
    "    batch_info = client.batches.retrieve(batch_id)\n",
    "    status = batch_info.status\n",
    "    print(f'Batch status: {status} - {batch_info.request_counts}')\n",
    "    if status == \"done\": break\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results of the batch\n",
    "batch_result = client.files.content(batch_info.output_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = list()\n",
    "for line in batch_result.iter_lines():\n",
    "    instance = json.loads(line)\n",
    "    problem_id = instance['custom_id'].split('-')[1]\n",
    "    model_response = instance['response']['choices'][0]['message']['content']\n",
    "    \n",
    "    try:\n",
    "        code = utils.extract_code_blocks(model_response)[0]['code']\n",
    "    except Exception as e:\n",
    "        print(f\"[-] No code blocks found. Will return the whole response.\")\n",
    "        code = model_response\n",
    "    \n",
    "    solutions.append({\"problem_id\": problem_id, \"solution\": code})\n",
    "    \n",
    "ds = Dataset.from_list(solutions)\n",
    "dataset_config = f\"{original_dataset_config}_{efficiency_instruction}_{afterburner_dataset_config}\"\n",
    "print(f'[+] Pushing {dataset_config} to hub...')\n",
    "if task == 'venus':\n",
    "    ds.push_to_hub(\"Elfsong/Venus_Model_Evaluation\", dataset_config, private=True)\n",
    "else:\n",
    "    ds.push_to_hub(\"Elfsong/Apps_Model_Evaluation\", dataset_config, private=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
